{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16b7dd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from utils import * \n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams['savefig.dpi'] = 400\n",
    "plt.rcParams['font.size'] = 13\n",
    "plt.rcParams[\"legend.frameon\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa51c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "train_path = \"gs://leap-persistent/jbusecke/data/climatebench/train_val/\"\n",
    "test_path = \"gs://leap-persistent/jbusecke/data/climatebench/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1213bc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Training set\u001b[39;00m\n\u001b[32m      2\u001b[39m train_files = [\u001b[33m\"\u001b[39m\u001b[33mhistorical\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mssp585\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mssp126\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mssp370\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mhist-aer\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mhist-GHG\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m X_train_xr, X_length  = \u001b[43mprepare_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m y_train_xr, y_length  = prepare_predictand(train_files,train_path)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Test set\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/EAEE4000_ML_EnvEng/utils.py:41\u001b[39m, in \u001b[36mprepare_predictor\u001b[39m\u001b[34m(data_sets, data_path, time_reindex)\u001b[39m\n\u001b[32m     38\u001b[39m X_all      = []\n\u001b[32m     39\u001b[39m length_all = []\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_sets\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     42\u001b[39m     data = open_dataset(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33minputs_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m     X_all.append(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/notebook.py:234\u001b[39m, in \u001b[36mtqdm_notebook.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    232\u001b[39m unit_scale = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m    233\u001b[39m total = \u001b[38;5;28mself\u001b[39m.total * unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[38;5;28mself\u001b[39m.container = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28mself\u001b[39m.container.pbar = proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.displayed = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/notebook.py:108\u001b[39m, in \u001b[36mtqdm_notebook.status_printer\u001b[39m\u001b[34m(_, total, desc, ncols)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[32m    110\u001b[39m     pbar = IProgress(\u001b[38;5;28mmin\u001b[39m=\u001b[32m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m=total)\n",
      "\u001b[31mImportError\u001b[39m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "# Training set\n",
    "train_files = [\"historical\", \"ssp585\", \"ssp126\", \"ssp370\",\"hist-aer\",\"hist-GHG\"]\n",
    "X_train_xr, X_length  = prepare_predictor(train_files,train_path)\n",
    "y_train_xr, y_length  = prepare_predictand(train_files,train_path)\n",
    "\n",
    "# Test set\n",
    "X_test_xr, _ = prepare_predictor('ssp245', data_path=test_path,time_reindex=False)\n",
    "y_test_xr, _ = prepare_predictand('ssp245',data_path=test_path,time_reindex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3b86a79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_xr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X_train_df = pd.DataFrame({\u001b[33m\"\u001b[39m\u001b[33mCO2\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mX_train_xr\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mCO2\u001b[39m\u001b[33m\"\u001b[39m].data,\n\u001b[32m      2\u001b[39m                            \u001b[33m\"\u001b[39m\u001b[33mCH4\u001b[39m\u001b[33m\"\u001b[39m: X_train_xr[\u001b[33m\"\u001b[39m\u001b[33mCH4\u001b[39m\u001b[33m\"\u001b[39m].data\n\u001b[32m      3\u001b[39m                           }, index=X_train_xr[\u001b[33m\"\u001b[39m\u001b[33mCO2\u001b[39m\u001b[33m\"\u001b[39m].coords[\u001b[33m'\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m'\u001b[39m].data)\n\u001b[32m      5\u001b[39m X_test_df  = pd.DataFrame({\u001b[33m\"\u001b[39m\u001b[33mCO2\u001b[39m\u001b[33m\"\u001b[39m: X_test_xr[\u001b[33m\"\u001b[39m\u001b[33mCO2\u001b[39m\u001b[33m\"\u001b[39m].data,\n\u001b[32m      6\u001b[39m                            \u001b[33m\"\u001b[39m\u001b[33mCH4\u001b[39m\u001b[33m\"\u001b[39m: X_test_xr[\u001b[33m\"\u001b[39m\u001b[33mCH4\u001b[39m\u001b[33m\"\u001b[39m].data\n\u001b[32m      7\u001b[39m                           }, index=X_test_xr[\u001b[33m\"\u001b[39m\u001b[33mCO2\u001b[39m\u001b[33m\"\u001b[39m].coords[\u001b[33m'\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m'\u001b[39m].data)\n\u001b[32m     10\u001b[39m y_train_df = y_train_xr[\u001b[33m\"\u001b[39m\u001b[33mtas\u001b[39m\u001b[33m\"\u001b[39m].stack({\u001b[33m\"\u001b[39m\u001b[33mstacked\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlatitude\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlongitude\u001b[39m\u001b[33m\"\u001b[39m)})\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train_xr' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_df = pd.DataFrame({\"CO2\": X_train_xr[\"CO2\"].data,\n",
    "                           \"CH4\": X_train_xr[\"CH4\"].data\n",
    "                          }, index=X_train_xr[\"CO2\"].coords['time'].data)\n",
    "\n",
    "X_test_df  = pd.DataFrame({\"CO2\": X_test_xr[\"CO2\"].data,\n",
    "                           \"CH4\": X_test_xr[\"CH4\"].data\n",
    "                          }, index=X_test_xr[\"CO2\"].coords['time'].data)\n",
    "\n",
    "\n",
    "y_train_df = y_train_xr[\"tas\"].stack({\"stacked\": (\"latitude\", \"longitude\")})\n",
    "y_train_df = pd.DataFrame(y_train_df.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c453050",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mX_train_df\u001b[49m.head()\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train_df' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b82a9ed8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43my_train_df\u001b[49m.head()\n",
      "\u001b[31mNameError\u001b[39m: name 'y_train_df' is not defined"
     ]
    }
   ],
   "source": [
    "y_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37fe22ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Standardization\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m mean, std = \u001b[43mX_train_df\u001b[49m.mean(), X_train_df.std()\n\u001b[32m      4\u001b[39m X_train_df   = (X_train_df - mean)/std\n\u001b[32m      5\u001b[39m X_test_df    = (X_test_df - mean)/std\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Standardization\n",
    "mean, std = X_train_df.mean(), X_train_df.std()\n",
    "\n",
    "X_train_df   = (X_train_df - mean)/std\n",
    "X_test_df    = (X_test_df - mean)/std\n",
    "\n",
    "X_train = X_train_df.to_numpy()\n",
    "y_train = y_train_df.to_numpy()\n",
    "X_test = X_test_df.to_numpy()\n",
    "\n",
    "print(X_train.shape,y_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6240dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators      = 300    # Number of trees in random forest\n",
    "min_samples_split = 10     # Minimum number of samples required to split a node\n",
    "min_samples_leaf  = 4      # Minimum number of samples required at each leaf node\n",
    "max_features      = None   # Number of features to consider at every split: 'sqrt', 'log2', or None.\n",
    "                           # None: max_features=n_feature\n",
    "max_depth         = 10     # Maximum number of levels in tree\n",
    "bootstrap         = True   # Method of selecting samples for training each tree\n",
    "\n",
    "reg0 = RandomForestRegressor(n_estimators=n_estimators,\n",
    "                             min_samples_split=min_samples_split,\n",
    "                             min_samples_leaf=min_samples_leaf,\n",
    "                             max_features=max_features,\n",
    "                             max_depth=max_depth,\n",
    "                             bootstrap=bootstrap)\n",
    "\n",
    "rf_tas = reg0.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd6081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 300, stop = 500, num = 5)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['sqrt', 'log2', None]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5,55, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [5, 10, 15, 25]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [4, 8, 12,16]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b9023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c70af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg0 = RandomForestRegressor(random_state=0)\n",
    "# perform cross validation\n",
    "rf_random0 = RandomizedSearchCV(estimator = reg0, param_distributions = random_grid, \n",
    "                                n_iter = 5, cv = 3, verbose=2, n_jobs = -1)\n",
    "rf_tas = rf_random0.fit(X_train,y_train)\n",
    "\n",
    "print(\"The best hyperparameters: \\n\",rf_tas.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a928515",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pre = rf_tas.predict(X_test)\n",
    "y_test_pre = y_test_pre.reshape(y_test_pre.shape[0], 96, 144)\n",
    "\n",
    "y_test_pre = xr.Dataset(coords={'time': X_test_xr.time.values, \n",
    "                               'latitude': X_test_xr.latitude.values, \n",
    "                               'longitude': X_test_xr.longitude.values},\n",
    "                        data_vars=dict(tas=(['time', 'latitude', 'longitude'], y_test_pre)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f1f83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(15,12),ncols=2,nrows=3)\n",
    "\n",
    "yrs = [2030, 2050, 2100]\n",
    "vmin, vmax    = -6, 6\n",
    "cmap = 'RdBu_r'\n",
    "y_test_pre.tas.sel(time=yrs[0]).plot(ax=axes[0,0], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "y_test_xr.tas.sel(time=yrs[0]).plot(ax=axes[0,1], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "\n",
    "y_test_pre.tas.sel(time=yrs[1]).plot(ax=axes[1,0], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "y_test_xr.tas.sel(time=yrs[1]).plot(ax=axes[1,1], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "\n",
    "y_test_pre.tas.sel(time=yrs[2]).plot(ax=axes[2,0], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "y_test_xr.tas.sel(time=yrs[2]).plot(ax=axes[2,1], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # left column: model prediction\n",
    "    if i % 2 == 0:\n",
    "        ax.set_title(f'tas model prediction (year = {yrs[i//2]})',fontweight='bold')\n",
    "    # right column: truth tas from ssp245 simulations\n",
    "    else:\n",
    "        ax.set_title(f'tas truth (year = {yrs[i//2]})',fontweight='bold')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6835aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "y_pred = reg0.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
